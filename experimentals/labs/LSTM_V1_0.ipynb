{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a99f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM caso 1: UNIVARIADO - CANTIDAD_VENTAS\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, LSTM\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "plt.rcParams['figure.figsize' ] = (16, 9)\n",
    "plt.style.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e8b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_server = \"\"\"\n",
    "DRIVER={ODBC Driver 17 for SQL Server};\n",
    "server=192.168.1.235,1433;\n",
    "database=demo_prediccion;\n",
    "uid=sa;\n",
    "pwd=qwerty;\n",
    "Trusted_connection=yes;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7385b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrenará con todos los datos de las ventas menores al 2020\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "[F].[Fecha] AS fecha,\n",
    "SUM([H]. [cantidad]) AS TotalVentas\n",
    "FROM\n",
    "[demo_prediccion]. [dbo]. [hechos] AS [H]\n",
    "INNER JOIN [demo_prediccion]. [dbo]. [Dim_fechas] AS [f] ON [H].[id_DimFechas] = [F].[id]\n",
    "WHERE \n",
    "[F].[Fecha] > '2016-12-31' AND [F].[Fecha] < '2020-01-01'\n",
    "GROUP BY [F].[Fecha]\n",
    "ORDER BY [F].[Fecha]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6594f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2=\"\"\"\n",
    "SELECT\n",
    "[F].[Fecha] AS fecha,\n",
    "SUM([H]. [cantidad]) AS TotalVentas\n",
    "FROM\n",
    "[demo_prediccion]. [dbo]. [hechos] AS [H]\n",
    "INNER JOIN [demo_prediccion]. [dbo]. [Dim_fechas] AS [f] ON [H].[id_DimFechas] = [F].[id]\n",
    "WHERE \n",
    "[F].[Fecha] > '2016-12-31' AND [F].[Fecha] < '2021-01-01'\n",
    "GROUP BY [F].[Fecha]\n",
    "ORDER BY [F].[Fecha]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a65b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTES\n",
    "\n",
    "PASOS = 31\n",
    "TRAINING_PERCENTAGE = 0.8\n",
    "N_PREDICTIONS = 31\n",
    "EPOCHS = 100\n",
    "NEURONS = 31 #Mismo que el de pasos\n",
    "\n",
    "\n",
    "#NOTAS DE ESTA PARTE: el número de pasos no es correlativo al No. de predicciones\n",
    "#ya que, las predicciones pudieran ser de 61 días y el No. de pasos siempre serán 31, ya que bajo\n",
    "#ese proceso se hizo el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f341064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion 1: Permitir que pueda ser modificada la sentencia, y mantener el try para evitar de que\n",
    "# el programa se rompa\n",
    "def get_sqlconnection(config_sqlServer):\n",
    "    status = \"inicializando....\"\n",
    "    try: \n",
    "        connection = pyodbc.connect(sql_server)\n",
    "        status = \"Conexion establecida satisfactoriamente\"\n",
    "    except Exception as e:\n",
    "        status = \"Error al establecer la conexión:\"+e\n",
    "    print(status)\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a387c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_index_datetime(data):\n",
    "        if str(type(data) == \"<class 'pandas.core.frame.DataFrame'>\"):\n",
    "            # data.sort_values('fecha', inplace=True)\n",
    "            for column in data.columns: \n",
    "                try: \n",
    "                    pd.to_datetime(data[column])\n",
    "                    data.set_index(column,inplace=True)\n",
    "                    return data\n",
    "                except Exception as e:  \n",
    "                    pass\n",
    "        else: \n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c976ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y_train(data):\n",
    "    values = data.values\n",
    "    values = values.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    values= values.reshape(-1, 1)\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "    values = reframed.values\n",
    "    \n",
    "    #debemos obtener el total de datos de entrenamiento\n",
    "    n_train_days = int(len(values) * TRAINING_PERCENTAGE)\n",
    "    print(\"Total de datos: \",int(len(values)))\n",
    "\n",
    "    #80% - entrenamiento \n",
    "    train = values[:n_train_days, :]\n",
    "    print(\"entrenamiento: \",len(train))\n",
    "\n",
    "    #20% - prueba\n",
    "    test = values[n_train_days:, :]\n",
    "    print(\"testing: \",len(test))\n",
    "    x_train, y_train = train[:, :- 1], train[:, -1]\n",
    "    x_val, y_val = test[:, :- 1], test[:, -1]\n",
    "    x_train = x_train.reshape((x_train.shape[0], PASOS, 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], PASOS,1))\n",
    "    print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "    return x_train, y_train, x_val, y_val, scaler, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28452c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val, data, scaler, model):\n",
    "    history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=PASOS, validation_data=(x_val, y_val), verbose=2, shuffle=False)\n",
    "\n",
    "    #Obtener el 20% de la data\n",
    "    ultimosDias = data[data.index[int(len(data)*TRAINING_PERCENTAGE)]:]\n",
    "    values = ultimosDias.values\n",
    "    values = values.astype('float32' )\n",
    "    values = values.reshape(-1, 1)\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "    reframed.drop(reframed.columns[[PASOS]], axis=1, inplace=True)\n",
    "    values = reframed.values\n",
    "    print(\"Meses registrados: \",len(values))\n",
    "    x_test = values[len(values)-1:, :]\n",
    "    print(\"La cantidad de días son: \",x_test.size)\n",
    "    #Tensor\n",
    "    x_test = x_test.reshape((x_test.shape[0], PASOS, x_test.shape[1]))\n",
    "    return model, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa82443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modeloLSTM():\n",
    "    input_shape = (PASOS,1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(NEURONS, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45afdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_anomalias(dtaframe):\n",
    "    dataFrame_anomalias = dtaframe.copy()\n",
    "    modeloIsolation = IsolationForest(contamination=0.05)\n",
    "    modeloIsolation.fit(dataFrame_anomalias)\n",
    "    anomalias = modeloIsolation.predict(dataFrame_anomalias)\n",
    "    dtaframe['anomalias' ] = anomalias\n",
    "    dataFrameSinAnomalias = dtaframe[dtaframe['anomalias' ] != -1]\n",
    "    dataFrameSinAnomalias = dataFrameSinAnomalias.drop('anomalias', axis=1)\n",
    "    return dataFrameSinAnomalias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNewValue(x_test,nuevoValor):\n",
    "    for i in range(x_test.shape[2]-1):\n",
    "        x_test[0][0][i] = x_test[0][0][i+1]\n",
    "    x_test[0][0][x_test.shape[2]-1]=nuevoValor[0]\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8937523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion establecida satisfactoriamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoCel\\AppData\\Local\\Temp\\ipykernel_22756\\1245306699.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  prepData = pd.read_sql_query(query,cursor)\n",
      "C:\\Users\\JoCel\\AppData\\Local\\Temp\\ipykernel_22756\\1245306699.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  historyData = pd.read_sql_query(query2, cursor)\n"
     ]
    }
   ],
   "source": [
    "#core\n",
    "with get_sqlconnection(sql_server) as cursor: \n",
    "    prepData = pd.read_sql_query(query,cursor)\n",
    "    historyData = pd.read_sql_query(query2, cursor)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04076d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalVentas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>7263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>12383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>11786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>12657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>16843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>17206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>17071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>17154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>28730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1094 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TotalVentas\n",
       "fecha                  \n",
       "2017-01-01         7263\n",
       "2017-01-02        13028\n",
       "2017-01-03        12383\n",
       "2017-01-04        11786\n",
       "2017-01-05        12657\n",
       "...                 ...\n",
       "2019-12-27        16843\n",
       "2019-12-28        17206\n",
       "2019-12-29        17071\n",
       "2019-12-30        17154\n",
       "2019-12-31        28730\n",
       "\n",
       "[1094 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    prepData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2a75ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    prepData = set_index_datetime(prepData)\n",
    "    historyData = set_index_datetime(historyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "865f856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Switch the format on days or months\n",
    "    #nota, acualmente los datos son filtrados con respecto a solo si son en  formato de día o de mes,\n",
    "    #en LSTM, que incluye  datos en horarios, se tendría que modificar esta parte\n",
    "    first_day = prepData.index.min() + timedelta(days=1)\n",
    "    last_day = prepData.index.max() + timedelta(days=1)\n",
    "    future_days = [last_day + timedelta(days=i) for i in range(PASOS)]\n",
    "    for i in range(len(future_days)):\n",
    "        future_days[i] = str(future_days[i])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #De momento solamente será la fecha\n",
    "    future_data = pd.DataFrame(future_days, columns=['fecha'])\n",
    "    \n",
    "    #creamos un modelo\n",
    "    for column in prepData.columns:\n",
    "        # data = prepData.filter([column])\n",
    "        data = prepData.filter([column])\n",
    "        data.set_index(prepData.index, inplace=True)\n",
    "        data = eliminar_anomalias(data)\n",
    "        x_train, y_train, x_val, y_val, scaler, values = create_x_y_train(data)\n",
    "        model, x_test = train_model(x_train, y_train,x_val, y_val,values,scaler,model)\n",
    "        copy_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        results = []\n",
    "        for i in range(N_PREDICTIONS):\n",
    "            parcial = model.predict(x_test)\n",
    "            results.append(parcial[0])\n",
    "            X_test = addNewValue(x_test,parcial[0])\n",
    "        adimen = np.array(results).reshape(-1, 1)\n",
    "        inverted = scaler.inverse_transform(adimen)\n",
    "        future_data[column] = inverted.astype(int)\n",
    "    future_data = set_index_datetime(future_data)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envprediccion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
